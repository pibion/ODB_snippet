{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "814a83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002080b",
   "metadata": {},
   "source": [
    "# function reading and writing the json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451d3c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "   \n",
    "def save_json_to_file(data, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e2a0ea",
   "metadata": {},
   "source": [
    "# removing the Keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f9f7f77-bf33-44b9-a348-d4f09d6e3917",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_slash_key_value(data, pattern=\"/key\"):\n",
    "    \"\"\"\n",
    "    Recursively removes keys from a dictionary if they contain the given pattern.\n",
    "\n",
    "    \"\"\"\n",
    "    if not isinstance(data, dict):\n",
    "        return data  # If data is not a dictionary, return as is\n",
    "    \n",
    "    new_dict = {}\n",
    "    for k, v in data.items():\n",
    "        if pattern not in k:  # Exclude keys that contain the pattern\n",
    "            if isinstance(v, dict):\n",
    "                new_dict[k] = filter_json_remove_slash_key_value(v, pattern)  # Recurse for nested dict\n",
    "            else:\n",
    "                new_dict[k] = v  # Keep the value as is\n",
    "    \n",
    "    return new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "214c2fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_system_keys(data):\n",
    "    # Ensure we only modify the 'System' key if it exists\n",
    "    if 'System' in data:\n",
    "        # List of keys to remove from 'System'\n",
    "        keys_to_remove = ['Buffers', 'Transition', 'Flush', 'Tmp']\n",
    "        \n",
    "        # Loop through the list and remove each key from 'System' if it exists\n",
    "        for key in keys_to_remove:\n",
    "            data['System'].pop(key, None)\n",
    "    # Filter out entries that have \"last_written\" in the key\n",
    "    if isinstance(data, list):  # Check if data is a list of dictionaries\n",
    "        data = [entry for entry in data if \"/last_written\" not in entry.get(\"key\", \"\")]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16862bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_json_remove_legacytrigger(data):\n",
    "    \"\"\"\n",
    "    This function recursively removes keys that match the pattern \"/Detectors/DetXX/Settings/LegacyTrigger\".\n",
    "    \"\"\"\n",
    "    def recursive_trim(d):\n",
    "        if isinstance(d, dict):\n",
    "            # Identify keys matching the specific pattern\n",
    "            keys_to_remove = [key for key in d if \"/Detectors/Det\" in key and \"/Settings/LegacyTrigger\" in key]\n",
    "            # Remove the matching keys\n",
    "            for key in keys_to_remove:\n",
    "                del d[key]\n",
    "            # Recursively process nested dictionaries or lists\n",
    "            for key, value in d.items():\n",
    "                if isinstance(value, (dict, list)):  # If the value is a dictionary or list, apply recursion\n",
    "                    recursive_trim(value)\n",
    "\n",
    "    # Call the recursive trim function on the data\n",
    "    recursive_trim(data)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fcaff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_differences(start_obj, end_obj):\n",
    "    def recursive_diff(start, end):\n",
    "        diff = {}\n",
    "        for key in end.keys():\n",
    "            if key not in start:\n",
    "                # Key is new in end_obj\n",
    "                diff[key] = end[key]\n",
    "            elif isinstance(start[key], dict) and isinstance(end[key], dict):\n",
    "                # Recursively check nested dictionaries\n",
    "                nested_diff = recursive_diff(start[key], end[key])\n",
    "                if nested_diff:  # Only add if there are differences\n",
    "                    diff[key] = nested_diff\n",
    "            elif isinstance(start[key], list) and isinstance(end[key], list):\n",
    "                # Compare lists directly\n",
    "                if start[key] != end[key]:\n",
    "                    diff[key] = end[key]\n",
    "            elif start[key] != end[key]:\n",
    "                # Value has changed\n",
    "                diff[key] = end[key]\n",
    "        return diff\n",
    "\n",
    "    return recursive_diff(start_obj, end_obj)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd378b54-a00b-484c-a36d-a453d3e017d8",
   "metadata": {},
   "source": [
    "# Saving into Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f129d8-cbee-451a-a965-f95000ea7dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving end Json\n"
     ]
    }
   ],
   "source": [
    "json2 = read_json_from_file('24250227_135126_end_original.json')\n",
    "json2 = filter_json_remove_slash_key_value(json2)\n",
    "save_json_to_file(json2, \"24250227_135126_end_remove_slash_key_value.json\")\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "save_json_to_file(json2, \"24250227_135126_end_remove_system_keys_except_clients.json\")\n",
    "\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "save_json_to_file(json2, \"24250227_135126_end_remove_legacytrigger.json\")\n",
    "\n",
    "print(\"saving end Json\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd23f019-5f59-41a4-9c21-3583a1ac5bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving start Json\n"
     ]
    }
   ],
   "source": [
    "json2 = read_json_from_file('24250227_135126_start_original.json')\n",
    "json2 = filter_json_remove_slash_key_value(json2)\n",
    "save_json_to_file(json2, \"24250227_135126_start_remove_slash_key_value.json\")\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "save_json_to_file(json2, \"24250227_135126_start_remove_system_keys_except_clients.json\")\n",
    "\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "save_json_to_file(json2, \"24250227_135126_start_remove_legacytrigger.json\")\n",
    "print(\"saving start Json\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7f93b-f9b6-45b5-ba9e-554424960de9",
   "metadata": {},
   "source": [
    "# Finding the difference in end json with the start after allabove filerting applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9743f39-fd56-4fed-9902-f55c3c7445e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logger': {'Channels': {'0': {'Settings': {'Current filename': '.RUN00075_DUMP0001.mid.gz'},\n",
       "    'Statistics': {'Disk level': 0.001500701734860943,\n",
       "     'Bytes written': 4489610,\n",
       "     'Files written': 20818,\n",
       "     'Events written': 361,\n",
       "     'Bytes written total': 17319883542959.0,\n",
       "     'Bytes written subrun': 2244248,\n",
       "     'Bytes written uncompressed': 69735101}}}},\n",
       " 'System': {'Clients': {'2049309': {'Run state': 1},\n",
       "   '2049311': {'Run state': 1}}},\n",
       " 'Runinfo': {'Stop time': 'Thu Feb 27 13:53:03 2025',\n",
       "  'Stop time binary': '0x67c0b48f',\n",
       "  'Transition in progress': 0},\n",
       " 'Equipment': {'EBlvl': {'Statistics': {'Events sent': 56}},\n",
       "  'EBuilder': {'Statistics': {'Events sent': 355},\n",
       "   'Special dump numbers': {'Last BORR': 1, 'Last BORTS': 1}},\n",
       "  'L2Trigger': {'Statistics': {'Events sent': 86}},\n",
       "  'readoutfe_SDU': {'Statistics': {'Events sent': 0}},\n",
       "  'readoutveto03': {'Statistics': {'Events sent': 10}},\n",
       "  'L2TriggerHistory': {'Statistics': {'Events sent': 10}},\n",
       "  'readouthistory03': {'Statistics': {'Events sent': 11}},\n",
       "  'readoutSDUhistory': {'Statistics': {'Events sent': 11}},\n",
       "  'Thermometry_RevF03': {'Statistics': {'Events sent': 2}}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json2 = read_json_from_file('24250227_135126_end_original.json')\n",
    "json2 = filter_json_remove_slash_key_value(json2)\n",
    "json2 = filter_json_remove_system_keys(json2)\n",
    "json2 = filter_json_remove_legacytrigger(json2)\n",
    "# json2 = filter_json_differ_Readback_Setting(json2)\n",
    "json1 = read_json_from_file('24250227_135126_start_original.json')\n",
    "json1 = filter_json_remove_slash_key_value(json1)\n",
    "json1 = filter_json_remove_system_keys(json1)\n",
    "finddifference=find_differences(json1,json2)\n",
    "finddifference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e998be66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving different in Json format\n"
     ]
    }
   ],
   "source": [
    "print(\"saving different in Json format\")\n",
    "save_json_to_file(finddifference, \"24250227_135126_diff_end_with_start_ODB.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7f4ec0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Action (odb end json for series=24250227_135126)        Disk Size (KB)\n",
      "===========================================================================\n",
      "Original_json                                                 11509.07\n",
      "Json_removing_slash_key_values                                 7612.37\n",
      "Json_removing_system_keys_except_clients                       7300.08\n",
      "Json_removing_legacytrigger                                    7300.08\n",
      "Json_difference_in_end_ODB_with_start                             7.77\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define file names corresponding to each step with sizes in KB\n",
    "file_sizes_on_disk = {\n",
    "    \"Original_json\": 11785291/1024,\n",
    "    \"Json_removing_slash_key_values\": 7795067 / 1024,\n",
    "    \"Json_removing_system_keys_except_clients\": 7475285 / 1024,\n",
    "    \"Json_removing_legacytrigger\": 7475285 / 1024,\n",
    "    \"Json_difference_in_end_ODB_with_start\": 7955/1024\n",
    "}\n",
    "print()\n",
    "# Print table header with better formatting\n",
    "print(f\"{'Action (odb end json for series=24250227_135126)':<50}{'Disk Size (KB)':>20}\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "# Print each file's disk size in a neatly formatted way\n",
    "for file_name, size_kb in file_sizes_on_disk.items():\n",
    "    print(f\"{file_name:<50}{size_kb:>20.2f}\")\n",
    "print()\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e6eccdc-533b-4428-bf63-10ed3ab3eb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Action (odb start json for series=24250227_135126)      Disk Size (KB)\n",
      "===========================================================================\n",
      "Original_json                                                 11506.38\n",
      "Json_removing_slash_key_values                                 7612.41\n",
      "Json_removing_system_keys_except_clients                       7300.08\n",
      "Json_removing_legacytrigger                                    7300.08\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define file names corresponding to each step with sizes in KB\n",
    "file_sizes_on_disk = {\n",
    "    \"Original_json\": 11782529/1024,\n",
    "    \"Json_removing_slash_key_values\": 7795110 / 1024,\n",
    "    \"Json_removing_system_keys_except_clients\": 7475284 / 1024,\n",
    "    \"Json_removing_legacytrigger\": 7475284 / 1024,\n",
    "    \n",
    "}\n",
    "print()\n",
    "# Print table header with better formatting\n",
    "print(f\"{'Action (odb start json for series=24250227_135126)':<50}{'Disk Size (KB)':>20}\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "# Print each file's disk size in a neatly formatted way\n",
    "for file_name, size_kb in file_sizes_on_disk.items():\n",
    "    print(f\"{file_name:<50}{size_kb:>20.2f}\")\n",
    "print()\n",
    "print()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac1252c-e5f7-455b-a2ed-0525b35cf7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
